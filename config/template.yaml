mode: train # (train / eval)
logger:
  level: 20 # CRITICAL = 50, ERROR = 40, WARNING = 30, INFO = 20, DEBUG = 10, NOTSET = 0
  format: "%(asctime)s - %(levelname)s - %(module)s - %(message)s"
device: cpu # (cuda / cpu / auto)
experiment_path: ..\experiments
epochs: 500

frequencies:
  save_freq: 1 # (i.e. how often should the model checkpoint be saved, in epochs)
  eval_freq: 1

dataloader:
  dataset: celebA
  size_fraction: 50000
  batch_size: 1

model:
  name: CDCGAN
  pretrained_path: # empty if start from scratch
  start_epoch: # empty if start from scratch
  criterion: BCELoss
  optimizer: Adam
  learning_rate: 0.001
  parameters:
    dropout: 0.2
    alpha: 0.1
    beta1: 0.1
    ngf: 64
    ndf: 64
    z_channels: 128
    use_spectral_norm: False
