slurmstepd-luhe: error: Unable to create TMPDIR [/tmp/user/31423]: Permission denied
slurmstepd-luhe: error: Setting TMPDIR to /tmp

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


Matplotlib is building the font cache; this may take a moment.
2022-09-08 19:13:30,563 - INFO - main - Successfully read the given configuration file, created experiment directory and set up logger.
2022-09-08 19:13:30,563 - INFO - main - Starting experiment in mode train using configuration ./experiments/config/ohlc_time/dqn/ex1.yaml
2022-09-08 19:13:30,564 - INFO - experiment - Initializing training experiment...
2022-09-08 19:13:30,564 - INFO - experiment - Using the following features as learnable parameters: ['time', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'real_volume']
2022-09-08 19:13:30,564 - INFO - experiment - Using time as learnable parameter: True
2022-09-08 19:13:34,997 - INFO - experiment - Using training data located in ./experiments/data/minmax/train.csv with length=77990 and shape=(77990, 8), and using testing data located in ./experiments/data/minmax/test.csv with length=19497 and shape=(19497, 8)
2022-09-08 19:13:34,997 - INFO - environment - Using action space: Discrete(2)
2022-09-08 19:13:34,997 - INFO - environment - Using observation space of shape: (30, 9)
2022-09-08 19:13:34,999 - INFO - environment - Using action space: Discrete(2)
2022-09-08 19:13:34,999 - INFO - environment - Using observation space of shape: (30, 9)
2022-09-08 19:13:35,001 - INFO - experiment - Using gym environment with window_size=30, scale_reward=1 and enable_render=False
2022-09-08 19:13:35,001 - INFO - agent - Initializing agent...
2022-09-08 19:13:35,043 - INFO - agent - Using device cuda
2022-09-08 19:13:35,043 - INFO - agent - Using policy MlpPolicy
2022-09-08 19:13:39,387 - INFO - agent - Using model DQN
2022-09-08 19:13:39,387 - INFO - agent - Successfully initialized agent
2022-09-08 19:13:39,387 - INFO - experiment - Successfully initialized training experiment
2022-09-08 19:13:39,387 - INFO - experiment - Starting training experiment...
2022-09-08 19:13:39,387 - INFO - experiment - Learning the agent...
/home/b/blenninger/arl22-rl-stock-trading/rltrading/gym/environment.py:106: RuntimeWarning: overflow encountered in double_scalars
  self._total_profit = quantity / curr_close
2022-09-09 00:52:31,201 - INFO - agent - Saved the model at ./experiments/results/ohlc_time/dqn/train/ex1/2022-09-08-19-13-30/model/episode-100
2022-09-09 00:52:31,202 - INFO - experiment - Finished learning the agent
2022-09-09 00:52:31,202 - INFO - experiment - Testing learned policy on test data...
2022-09-09 00:53:15,396 - INFO - agent - Saved the results at ./experiments/results/ohlc_time/dqn/train/ex1/2022-09-08-19-13-30/stats
2022-09-09 00:53:15,694 - INFO - experiment - Finished testing the learned policy on test data
2022-09-09 00:53:22,264 - INFO - main - Successfully read the given configuration file, created experiment directory and set up logger.
2022-09-09 00:53:22,264 - INFO - main - Starting experiment in mode train using configuration ./experiments/config/ohlc_time/dqn/ex2.yaml
2022-09-09 00:53:22,264 - INFO - experiment - Initializing training experiment...
2022-09-09 00:53:22,265 - INFO - experiment - Using the following features as learnable parameters: ['time', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'real_volume']
2022-09-09 00:53:22,265 - INFO - experiment - Using time as learnable parameter: True
2022-09-09 00:53:24,356 - INFO - experiment - Using training data located in ./experiments/data/minmax/train.csv with length=77990 and shape=(77990, 8), and using testing data located in ./experiments/data/minmax/test.csv with length=19497 and shape=(19497, 8)
2022-09-09 00:53:24,357 - INFO - environment - Using action space: Discrete(2)
2022-09-09 00:53:24,357 - INFO - environment - Using observation space of shape: (30, 9)
2022-09-09 00:53:24,358 - INFO - environment - Using action space: Discrete(2)
2022-09-09 00:53:24,358 - INFO - environment - Using observation space of shape: (30, 9)
2022-09-09 00:53:24,360 - INFO - experiment - Using gym environment with window_size=30, scale_reward=1 and enable_render=False
2022-09-09 00:53:24,360 - INFO - agent - Initializing agent...
2022-09-09 00:53:24,404 - INFO - agent - Using device cuda
2022-09-09 00:53:24,404 - INFO - agent - Using policy MlpPolicy
2022-09-09 00:53:26,016 - INFO - agent - Using model DQN
2022-09-09 00:53:26,017 - INFO - agent - Successfully initialized agent
2022-09-09 00:53:26,017 - INFO - experiment - Successfully initialized training experiment
2022-09-09 00:53:26,017 - INFO - experiment - Starting training experiment...
2022-09-09 00:53:26,017 - INFO - experiment - Learning the agent...
/home/b/blenninger/arl22-rl-stock-trading/rltrading/gym/environment.py:106: RuntimeWarning: overflow encountered in double_scalars
  self._total_profit = quantity / curr_close
2022-09-09 06:30:35,936 - INFO - agent - Saved the model at ./experiments/results/ohlc_time/dqn/train/ex2/2022-09-09-00-53-22/model/episode-100
2022-09-09 06:30:35,937 - INFO - experiment - Finished learning the agent
2022-09-09 06:30:35,937 - INFO - experiment - Testing learned policy on test data...
2022-09-09 06:31:18,809 - INFO - agent - Saved the results at ./experiments/results/ohlc_time/dqn/train/ex2/2022-09-09-00-53-22/stats
2022-09-09 06:31:18,901 - INFO - experiment - Finished testing the learned policy on test data
2022-09-09 06:31:24,946 - INFO - main - Successfully read the given configuration file, created experiment directory and set up logger.
2022-09-09 06:31:24,947 - INFO - main - Starting experiment in mode train using configuration ./experiments/config/ohlc_time/dqn/ex3.yaml
2022-09-09 06:31:24,947 - INFO - experiment - Initializing training experiment...
2022-09-09 06:31:24,947 - INFO - experiment - Using the following features as learnable parameters: ['time', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'real_volume']
2022-09-09 06:31:24,947 - INFO - experiment - Using time as learnable parameter: True
2022-09-09 06:31:27,042 - INFO - experiment - Using training data located in ./experiments/data/minmax/train.csv with length=77990 and shape=(77990, 8), and using testing data located in ./experiments/data/minmax/test.csv with length=19497 and shape=(19497, 8)
2022-09-09 06:31:27,042 - INFO - environment - Using action space: Discrete(2)
2022-09-09 06:31:27,042 - INFO - environment - Using observation space of shape: (30, 9)
2022-09-09 06:31:27,044 - INFO - environment - Using action space: Discrete(2)
2022-09-09 06:31:27,044 - INFO - environment - Using observation space of shape: (30, 9)
2022-09-09 06:31:27,046 - INFO - experiment - Using gym environment with window_size=30, scale_reward=1 and enable_render=False
2022-09-09 06:31:27,046 - INFO - agent - Initializing agent...
2022-09-09 06:31:27,092 - INFO - agent - Using device cuda
2022-09-09 06:31:27,092 - INFO - agent - Using policy MlpPolicy
2022-09-09 06:31:28,712 - INFO - agent - Using model DQN
2022-09-09 06:31:28,713 - INFO - agent - Successfully initialized agent
2022-09-09 06:31:28,713 - INFO - experiment - Successfully initialized training experiment
2022-09-09 06:31:28,713 - INFO - experiment - Starting training experiment...
2022-09-09 06:31:28,713 - INFO - experiment - Learning the agent...
/home/b/blenninger/arl22-rl-stock-trading/rltrading/gym/environment.py:106: RuntimeWarning: overflow encountered in double_scalars
  self._total_profit = quantity / curr_close
2022-09-09 12:07:15,260 - INFO - agent - Saved the model at ./experiments/results/ohlc_time/dqn/train/ex3/2022-09-09-06-31-24/model/episode-100
2022-09-09 12:07:15,261 - INFO - experiment - Finished learning the agent
2022-09-09 12:07:15,261 - INFO - experiment - Testing learned policy on test data...
/home/b/blenninger/arl22-rl-stock-trading/rltrading/gym/environment.py:106: RuntimeWarning: overflow encountered in double_scalars
  self._total_profit = quantity / curr_close
2022-09-09 12:07:58,512 - INFO - agent - Saved the results at ./experiments/results/ohlc_time/dqn/train/ex3/2022-09-09-06-31-24/stats
2022-09-09 12:07:58,603 - INFO - experiment - Finished testing the learned policy on test data
